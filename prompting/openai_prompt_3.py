import openai
import time
import pandas as pd
import json
import csv
from secret_key import openai_key

openai.api_key = openai_key

output_file = "predictions/gpt4/prompt_level_3.csv"

RUBRICS = ["organization", "vocabulary", "style", "development", "mechanics", "structure", "relevance"]

RUBRIC_GUIDES = {
    "organization": {
        "arabic": "ÿßŸÑÿ™ŸÜÿ∏ŸäŸÖ",
        "guide": "1. ŸáŸÑ ÿßŸÑŸÖŸÇÿßŸÑ ŸÖŸÜÿ∏ŸÖ ÿ¨ŸäÿØŸãÿßÿü\n2. ŸáŸÑ ŸáŸÜÿßŸÉ ŸÖŸÇÿØŸÖÿ© Ÿàÿ¨ÿ≥ŸÖ ŸàÿÆÿßÿ™ŸÖÿ© Ÿàÿßÿ∂ÿ≠ÿ©ÿü\n3. ŸáŸÑ ÿ™ÿ≥ŸÑÿ≥ŸÑ ÿßŸÑŸÅŸÇÿ±ÿßÿ™ ŸÖŸÜÿ∑ŸÇŸäÿü",
        "scoring": "0-5"
    },
    "vocabulary": {
        "arabic": "ÿßŸÑŸÖŸÅÿ±ÿØÿßÿ™",
        "guide": "1. ŸÖÿß ŸÖÿØŸâ ÿ™ŸÜŸàÿπ ÿßŸÑŸÖŸÅÿ±ÿØÿßÿ™ÿü\n2. ŸáŸÑ ŸäŸàÿ¨ÿØ ÿ™ŸÉÿ±ÿßÿ± ÿ£Ÿà ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ∫Ÿäÿ± ŸÖŸÜÿßÿ≥ÿ®ÿü\n3. ŸáŸÑ ÿßŸÑŸÖŸÅÿ±ÿØÿßÿ™ ÿØŸÇŸäŸÇÿ© Ÿàÿ™ÿÆÿØŸÖ ÿßŸÑŸÖÿπŸÜŸâÿü",
        "scoring": "0-5"
    },
    "style": {
        "arabic": "ÿßŸÑÿ£ÿ≥ŸÑŸàÿ®",
        "guide": "1. ŸáŸÑ ÿßŸÑÿ£ÿ≥ŸÑŸàÿ® ŸÖŸÑÿßÿ¶ŸÖ Ÿàÿ¥ŸäŸÇÿü\n2. ŸáŸÑ ÿ™Ÿàÿ¨ÿØ ÿ≥ŸÑÿßÿ≥ÿ© ŸÅŸä ÿßŸÑÿ™ÿπÿ®Ÿäÿ±ÿü\n3. ŸáŸÑ ÿßŸÑÿ™ÿ±ÿßŸÉŸäÿ® ŸàÿßŸÑÿ£ÿ≥ÿßŸÑŸäÿ® ŸÖŸÜÿßÿ≥ÿ®ÿ©ÿü",
        "scoring": "0-5"
    },
    "development": {
        "arabic": "ÿ™ÿ∑ŸàŸäÿ± ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ",
        "guide": "1. ŸáŸÑ ÿ™ŸÖ ÿØÿπŸÖ ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿ®ÿ£ŸÖÿ´ŸÑÿ©ÿü\n2. ŸáŸÑ ŸáŸÜÿßŸÉ ÿ™ŸÅÿµŸäŸÑ ŸÉÿßŸÅŸçÿü\n3. ŸáŸÑ ÿßŸÑÿ≠ÿ¨ÿ© ŸÖŸÇŸÜÿπÿ©ÿü",
        "scoring": "0-5"
    },
    "mechanics": {
        "arabic": "ÿßŸÑŸÖŸäŸÉÿßŸÜŸäŸÉÿß ÿßŸÑŸÑÿ∫ŸàŸäÿ©",
        "guide": "1. ŸáŸÑ ÿ™Ÿàÿ¨ÿØ ÿ£ÿÆÿ∑ÿßÿ° ŸÜÿ≠ŸàŸäÿ© ÿ£Ÿà ÿ•ŸÖŸÑÿßÿ¶Ÿäÿ©ÿü\n2. ŸáŸÑ ÿπŸÑÿßŸÖÿßÿ™ ÿßŸÑÿ™ÿ±ŸÇŸäŸÖ ŸÖÿ≥ÿ™ÿÆÿØŸÖÿ© ÿ®ÿ¥ŸÉŸÑ ÿµÿ≠Ÿäÿ≠ÿü",
        "scoring": "0-5"
    },
    "structure": {
        "arabic": "ÿßŸÑÿ™ÿ±ÿßŸÉŸäÿ® ÿßŸÑŸÜÿ≠ŸàŸäÿ©",
        "guide": "1. ŸáŸÑ ÿßŸÑÿ¨ŸÖŸÑ ÿ≥ŸÑŸäŸÖÿ©ÿü\n2. ŸáŸÑ ÿßŸÑÿ™ÿ±ŸÉŸäÿ® ÿßŸÑŸÜÿ≠ŸàŸä Ÿàÿßÿ∂ÿ≠ ŸàŸÖŸÜÿ∂ÿ®ÿ∑ÿü",
        "scoring": "0-5"
    },
    "relevance": {
        "arabic": "ŸÖÿØŸâ ÿßŸÑÿµŸÑÿ© ÿ®ÿßŸÑŸÖŸàÿ∂Ÿàÿπ",
        "guide": "1. ŸáŸÑ ÿßŸÑŸÖŸÇÿßŸÑ ŸäÿπÿßŸÑÿ¨ ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ™ŸàÿßÿµŸÑ ŸàÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿßÿü\n2. ŸáŸÑ ÿ™ŸÜÿ≥ÿ¨ŸÖ ÿßŸÑŸÅŸÉÿ±ÿ© ÿßŸÑÿπÿßŸÖÿ© ŸÖÿπ ÿßŸÑŸÖŸàÿ∂Ÿàÿπÿü",
        "scoring": "0-2"
    }
}

def build_system_prompt(rubric, max_tokens=7000):
    info = RUBRIC_GUIDES[rubric]
    with open(f"rubric_examples/{rubric}.txt", encoding='utf-8') as f:
        example = f.read()

    # Truncate rubric example if too long
    if len(example) > 3000:
        print(f"‚ö†Ô∏è Truncating example for rubric: {rubric}")
        example = example[:3000] + "\n...[truncated]"

    return f"""ÿ£ŸÜÿ™ ŸÖŸÇŸäŸÖ ŸÑÿ∫ŸàŸä ŸÖÿÆÿ™ÿµ ŸÅŸä ÿ™ŸÇŸäŸäŸÖ ŸÖŸáÿßÿ±ÿ© [{info['arabic']}] ŸÅŸä ÿßŸÑŸÖŸÇÿßŸÑÿßÿ™ ÿßŸÑŸÖŸÉÿ™Ÿàÿ®ÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©.

ÿ≥ÿ™ŸÇŸàŸÖ ÿ®ÿ™ŸÇŸäŸäŸÖ ÿßŸÑŸÖŸÇÿßŸÑ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ Ÿáÿ∞Ÿá ÿßŸÑŸÖŸáÿßÿ±ÿ© ŸÅŸÇÿ∑.

Ÿäÿ±ÿ¨Ÿâ ÿßÿ™ÿ®ÿßÿπ ÿßŸÑÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑÿ™ÿßŸÑŸäÿ©:
1. ÿßŸÇÿ±ÿ£ ÿßŸÑŸÖŸÇÿßŸÑ ÿ¨ŸäÿØÿßŸã.
2. ÿßÿ™ÿ®ÿπ ÿØŸÑŸäŸÑ ÿßŸÑÿ™ŸÇŸäŸäŸÖ ÿßŸÑÿ™ÿßŸÑŸä:
{info['guide']}
3. ÿ≠ÿØÿØ ÿØÿ±ÿ¨ÿ© ŸÖŸÜ {info['scoring']}.
4. ŸÇÿØŸÖ ŸÖÿ®ÿ±ÿ±ÿßÿ™ Ÿàÿßÿ∂ÿ≠ÿ© ŸÑŸÇÿ±ÿßÿ±ŸÉ.

Ÿäÿ™ÿ∂ŸÖŸÜ ÿßŸÑŸÖÿπŸäÿßÿ± ÿ£ÿØŸÜÿßŸá:
- ŸàÿµŸÅŸãÿß ŸÑŸÖÿß ŸäŸÇŸäÿ≥Ÿá
- ÿ´ŸÑÿßÿ´ÿ© ŸÖÿ≥ÿ™ŸàŸäÿßÿ™ ŸÉÿ£ŸÖÿ´ŸÑÿ© (ÿßŸÑÿØÿ±ÿ¨ÿßÿ™: Ÿ°ÿå Ÿ£ÿå Ÿ•)

\"\"\"
{example}
\"\"\"

ÿßÿ≥ÿ™ÿÆÿØŸÖ Ÿáÿ∞Ÿá ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© ŸÑŸÖŸÇÿßÿ±ŸÜÿ© ÿßŸÑŸÖŸÇÿßŸÑ ÿßŸÑÿ∞Ÿä ÿ™ŸÇŸàŸÖ ÿ®ÿ™ŸÇŸäŸäŸÖŸá Ÿàÿ™ÿ®ÿ±Ÿäÿ± ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ© ŸàŸÅŸÇŸãÿß ŸÑÿ∞ŸÑŸÉ.

ÿ£ÿ¨ÿ® ÿ®ÿµŸäÿ∫ÿ© JSON ŸÅŸÇÿ∑ ÿ®Ÿáÿ∞ÿß ÿßŸÑÿ¥ŸÉŸÑ:
{{
    "score": X,
    "justification": "..."
}}
"""

def build_user_prompt(essay_text, max_chars=2000):
    # Truncate long essay
    if len(essay_text) > max_chars:
        print("‚ö†Ô∏è Truncating essay text")
        essay_text = essay_text[:max_chars] + "\n...[truncated]"

    return f""" ÿßŸÑŸÖŸÇÿßŸÑ:
\"\"\"
{essay_text}
\"\"\"
"""


def get_gpt4_response(system_prompt, user_prompt):
    while True:
        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=messages,
                temperature=0
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"‚ùå Error: {e}")
            time.sleep(10)

df = pd.read_excel("dataset.xlsx")
results = []

for essay_id, essay_text in zip(df['essay_id'], df['text']):
    print(f"üìù Scoring Essay ID: {essay_id}")
    row = {"essay_id": essay_id}
    total = 0

    for rubric in RUBRICS:
        system_prompt = build_system_prompt(rubric)
        user_prompt = build_user_prompt(essay_text)

        output = get_gpt4_response(system_prompt, user_prompt)
        print(f"üìú GPT Output for {rubric}:\n{output}")

        try:
            json_start = output.find('{')
            json_end = output.rfind('}') + 1
            json_str = output[json_start:json_end]
            parsed = json.loads(json_str)

            score = float(parsed.get("score", 0))
            score = int(min(score, 2 if rubric == "relevance" else 5))
        except Exception as e:
            print(f"‚ö†Ô∏è Parsing error for {rubric}: {e}")
            score = 0

        row[rubric] = score
        total += score

    row["final_score"] = round(total)
    row["total_score"] = round(total)

    results.append(row)
    time.sleep(15)

fieldnames = ["essay_id"] + RUBRICS + ["final_score", "total_score"]

with open(output_file, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(results)

print(f"üíæ Saved GPT-4 results to {output_file}")
