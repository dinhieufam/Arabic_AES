# -*- coding: utf-8 -*-

import pandas as pd
import torch
import json
import csv
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor

model_path = "Qwen/Qwen3-VL-8B-Instruct"

RUBRICS = ["organization", "vocabulary", "style", "development", "mechanics", "structure", "relevance"]

RUBRIC_GUIDES = {
    "organization": {
        "arabic": "Ø§Ù„ØªÙ†Ø¸ÙŠÙ…",
        "guide": "1. Ù‡Ù„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù…Ù†Ø¸Ù… Ø¬ÙŠØ¯Ù‹Ø§ØŸ\n2. Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ù…Ù‚Ø¯Ù…Ø© ÙˆØ¬Ø³Ù… ÙˆØ®Ø§ØªÙ…Ø© ÙˆØ§Ø¶Ø­Ø©ØŸ\n3. Ù‡Ù„ ØªØ³Ù„Ø³Ù„ Ø§Ù„ÙÙ‚Ø±Ø§Øª Ù…Ù†Ø·Ù‚ÙŠØŸ",
        "scoring": "0-5"
    },
    "vocabulary": {
        "arabic": "Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª",
        "guide": "1. Ù…Ø§ Ù…Ø¯Ù‰ ØªÙ†ÙˆØ¹ Ø§Ù„Ù…ÙØ±Ø¯Ø§ØªØŸ\n2. Ù‡Ù„ ÙŠÙˆØ¬Ø¯ ØªÙƒØ±Ø§Ø± Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨ØŸ\n3. Ù‡Ù„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù†Ù‰ØŸ",
        "scoring": "0-5"
    },
    "style": {
        "arabic": "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨",
        "guide": "1. Ù‡Ù„ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ù…Ù„Ø§Ø¦Ù… ÙˆØ´ÙŠÙ‚ØŸ\n2. Ù‡Ù„ ØªÙˆØ¬Ø¯ Ø³Ù„Ø§Ø³Ø© ÙÙŠ Ø§Ù„ØªØ¹Ø¨ÙŠØ±ØŸ\n3. Ù‡Ù„ Ø§Ù„ØªØ±Ø§ÙƒÙŠØ¨ ÙˆØ§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ù…Ù†Ø§Ø³Ø¨Ø©ØŸ",
        "scoring": "0-5"
    },
    "development": {
        "arabic": "ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø­ØªÙˆÙ‰",
        "guide": "1. Ù‡Ù„ ØªÙ… Ø¯Ø¹Ù… Ø§Ù„Ø£ÙÙƒØ§Ø± Ø¨Ø£Ù…Ø«Ù„Ø©ØŸ\n2. Ù‡Ù„ Ù‡Ù†Ø§Ùƒ ØªÙØµÙŠÙ„ ÙƒØ§ÙÙØŸ\n3. Ù‡Ù„ Ø§Ù„Ø­Ø¬Ø© Ù…Ù‚Ù†Ø¹Ø©ØŸ",
        "scoring": "0-5"
    },
    "mechanics": {
        "arabic": "Ø§Ù„Ù…ÙŠÙƒØ§Ù†ÙŠÙƒØ§ Ø§Ù„Ù„ØºÙˆÙŠØ©",
        "guide": "1. Ù‡Ù„ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡ Ù†Ø­ÙˆÙŠØ© Ø£Ùˆ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©ØŸ\n2. Ù‡Ù„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ØŸ",
        "scoring": "0-5"
    },
    "structure": {
        "arabic": "Ø§Ù„ØªØ±Ø§ÙƒÙŠØ¨ Ø§Ù„Ù†Ø­ÙˆÙŠØ©",
        "guide": "1. Ù‡Ù„ Ø§Ù„Ø¬Ù…Ù„ Ø³Ù„ÙŠÙ…Ø©ØŸ\n2. Ù‡Ù„ Ø§Ù„ØªØ±ÙƒÙŠØ¨ Ø§Ù„Ù†Ø­ÙˆÙŠ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ù†Ø¶Ø¨Ø·ØŸ",
        "scoring": "0-5"
    },
    "relevance": {
        "arabic": "Ù…Ø¯Ù‰ Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹",
        "guide": "1. Ù‡Ù„ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙŠØ¹Ø§Ù„Ø¬ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ØªÙˆØ§ØµÙ„ ÙˆØ§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ØŸ\n2. Ù‡Ù„ ØªÙ†Ø³Ø¬Ù… Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø¹ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŸ",
        "scoring": "0-2"
    }
}

def build_prompt(rubric, essay_text):
    rubric_info = RUBRIC_GUIDES[rubric]

    with open(f'../rubric_examples/{rubric}.txt', 'r', encoding='utf-8') as f:
        example = f.read()

    return f"""
Ø£Ù†Øª Ù…Ù‚ÙŠÙ… Ù„ØºÙˆÙŠ Ù…Ø®ØªØµ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ù…Ù‡Ø§Ø±Ø© [{rubric_info['arabic']}] ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

Ø³ØªÙ‚ÙˆÙ… Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ø§Ø±Ø© ÙÙ‚Ø·.

ÙŠØ±Ø¬Ù‰ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
1. Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¬ÙŠØ¯Ø§Ù‹.
2. Ø§ØªØ¨Ø¹ Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ§Ù„ÙŠ:
{rubric_info['guide']}
3. Ø­Ø¯Ø¯ Ø¯Ø±Ø¬Ø© Ù…Ù† {rubric_info['scoring']}.
4. Ù‚Ø¯Ù… Ù…Ø¨Ø±Ø±Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ù„Ù‚Ø±Ø§Ø±Ùƒ.

ÙŠØªØ¶Ù…Ù† Ø§Ù„Ù…Ø¹ÙŠØ§Ø± Ø£Ø¯Ù†Ø§Ù‡:
- ÙˆØµÙÙ‹Ø§ Ù„Ù…Ø§ ÙŠÙ‚ÙŠØ³Ù‡
- Ø«Ù„Ø§Ø«Ø© Ù…Ø³ØªÙˆÙŠØ§Øª ÙƒØ£Ù…Ø«Ù„Ø© (Ø§Ù„Ø¯Ø±Ø¬Ø§Øª: Ù¡ØŒ Ù£ØŒ Ù¥)
\"\"\"
{example}
\"\"\"
Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø°ÙŠ ØªÙ‚ÙˆÙ… Ø¨ØªÙ‚ÙŠÙŠÙ…Ù‡ ÙˆØªØ¨Ø±ÙŠØ± Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆÙÙ‚Ù‹Ø§ Ù„Ø°Ù„Ùƒ.

Ø§Ù„Ù…Ù‚Ø§Ù„:
\"\"\"
{essay_text}
\"\"\"

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:
{{
    "score": X,
    "justification": "..."
}}
"""

prompt_eng = "### Instruction: You are a helpful assistant. Complete the conversation between [|Human|] and [|AI|]:\n### Input: [|Human|] {Question}\n[|AI|]\n### Response :"

# Load model and processor
model = Qwen3VLForConditionalGeneration.from_pretrained(model_path, dtype="auto", device_map="auto")
processor = AutoProcessor.from_pretrained(model_path)

def get_response(text, processor=processor, model=model):
    # Prepare messages for the model
    messages = [
        {
            "role": "user", 
            "content": [
                {"type": "text", "text": text}
            ]
        }
    ]
    
    # Apply chat template and prepare inputs
    inputs = processor.apply_chat_template(
        messages,
        tokenize=True,
        add_generation_prompt=True,
        return_dict=True,
        return_tensors="pt"
    )
    inputs = inputs.to(model.device)

    # Generate response
    with torch.no_grad():
        generated_ids = model.generate(**inputs, max_new_tokens=512)
        
    # Process generated output
    generated_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    ]
    
    output_text = processor.batch_decode(
        generated_ids_trimmed,
        skip_special_tokens=True,
        clean_up_tokenization_spaces=False
    )[0]
    
    return output_text

df = pd.read_excel("../dataset.xlsx")
results = []

for essay_id, essay_text in zip(df['essay_id'], df['text']):
    print("Processing the essay with ID: ", essay_id)
    row = {"essay_id": essay_id}
    total = 0
    for rubric in RUBRICS:
        # Run the model and parse the response
        prompt = prompt_eng.format_map({'Question': build_prompt(rubric, essay_text)})
        output = get_response(prompt)

        print("ğŸ” Output:\n", output)

        json_data = {}
        try:
            # Find JSON in response
            json_start = output.find('{')
            json_end = output.rfind('}') + 1
            json_str = output[json_start:json_end]
            
            # Parse scores
            json_data = json.loads(json_str)
            json_data["score"] = int(min(float(json_data["score"]), 5)) if rubric != "relevance" else int(min(float(json_data["score"]), 2))
            
        except Exception as e:
            json_data = {"score": 0, "justification": f"Parsing error: {str(e)}"}

        # Add the score to the row
        row[rubric] = json_data["score"]

        # Add the score to the total
        total += json_data["score"]

        print(f"ğŸ“Œ {rubric}: {json_data['score']}")

    row["final_score"] = round(total)
    row["total_score"] = round(total)

    print(row)

    results.append(row)

# Save results to CSV
output_file = "../predictions/qwen3vl/prompt_3.csv"
fieldnames = ["essay_id", "organization", "vocabulary", "style", "development", 
              "mechanics", "structure", "relevance", "final_score", "total_score"]

with open(output_file, "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(results)

print(f"ğŸ’¾ Saved results to {output_file}")